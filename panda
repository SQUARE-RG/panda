#!/usr/bin/env python3
#-*- encoding: utf-8 -*-

#################################################
#  See Copyright Notice in file `LICENSE.txt`.  #
#################################################

import traceback
import os
import sys
import json
import argparse
import multiprocessing as mp
import subprocess as proc
import time
import re
import heapq
from queue import Queue
from queue import PriorityQueue
from queue import Empty as QueueEmptyException
import numpy as np


# Utils {{{
def log(msg, opts=None):
    if opts is not None and log.verbose is None:
        log.verbose = opts.verbose
    if log.verbose is True:
        print('-- ' + msg, file=sys.stderr)
log.verbose = None


def fatal(msg): sys.exit('-- ' + msg)
def warn(msg): print('-- ' + msg, file=sys.stderr)


def PrintExcutionInfo():
    print('Total execution time: %.3lf sec' %
            (time.time() - PrintExcutionInfo.start_time))


def mkdir(dirname):
    log('!: mkdir -p %s' % dirname)
    if not os.path.exists(dirname):
        try:
            os.makedirs(dirname)
        except FileExistsError:  # may happen when multi-thread
            pass


# File type: clang::driver::types::lookupTypeForExtension
def InferLanguage(path):
    extname = os.path.splitext(path)[1][1:]
    if extname == 'c':
        return 'c'
    elif extname in {'C', 'cc', 'CC', 'cp', 'cpp', 'CPP',
            'cxx', 'CXX', 'c++', 'C++'}:
        return 'c++'
#   elif extname == 'i':
#       return 'PP-C'
#   elif extname == 'ii':
#       return 'PP-C++'
    else:
        return 'Unknown'


class CompileCommands:
    def __init__(self, ccmd=None):
        self.compiler = None
        self.file = None
        self.directory = None
        self.arguments = None
        self.language = None
        if ccmd:
            self.parse(ccmd)

    def __str__(self):
        return json.dumps(
                {
                    'arguments': self.arguments,
                    'directory': self.directory,
                    'file': self.file,
                    'compiler': self.compiler,
                    'language': self.language,
                }, indent=4)

    def parse(self, ccmd):
        # Check the validity of a compile command.
        if not CompileCommands.isValidCompileCommand(ccmd):
            warn('W: Invalid compile command object.\n' +
                     json.dumps(ccmd, indent=4))
            return None

        # directoy and file
        self.directory = os.path.abspath(ccmd['directory'])
        self.file = os.path.abspath(os.path.join(
            self.directory, ccmd['file']))

        self.language = InferLanguage(self.file)

        # command => arguments
        arguments = None
        if 'command' in ccmd:
            from shlex import split
            arguments = split(ccmd['command'])
        else:
            arguments = ccmd['arguments']

        # compiler
        self.compiler = arguments[0]

        # Adjust arguments.
        i, n = 0, len(arguments)
        self.arguments = []
        prune1 = {'-c', '-fsyntax-only', '-save-temps'}
        prune2 = {'-o', '-MF', '-MT', '-MQ', '-MJ'}
        prunes2 = {'-M', '-W', '-g'}
        while True:
            i += 1
            if i >= n:
                break
            if arguments[i] in prune1:
                continue
            if arguments[i] in prune2:
                i += 1
                continue
            if arguments[i][:3] == '-o=':
                continue
            if arguments[i][:2] in prunes2:
                continue
            self.arguments.append(arguments[i])
            # Reset language if provided in command line arguments.
            if arguments[i] == '-x':
                self.language = arguments[i + 1]
            elif arguments[i][:2] == '-x':
                self.language = arguments[i][2:]

        return self


    @staticmethod
    def isValidCompileCommand(ccmd):
        return 'file' in ccmd and 'directory' in ccmd and \
                ('arguments' in ccmd or 'command' in ccmd)


# Collecting code feature vector from source code.
class CodeFeature:
    ider = re.compile(r'\b[a-zA-Z_][a-zA-Z0-9_]*\b')
    keywords = [
        'const', 'auto', 'char', 'bool', 'false', 'true', 'if', 'for', 'while',
        'template', 'nullptr'
    ]
    kwre = re.compile(r'\b' + r'\b|\b'.join(keywords) + r'\b')
    count = [
        ('string', '"'), ('block', '{'), ('include', '<'), ('stmt', ';'),
        ('bcom', '/*'), ('lcom', '//'), ('para', '('),
        ('arrow', '->'), ('addr', '&'), ('mul', '*'), ('equal', '='),
        ('dot', '.'), ('add', '+'), ('not', '!')
    ]

    @staticmethod
    def dumpFeatures(f):
        print('# ' + ', '.join(CodeFeature.keywords), file=f)
        print('# ' + ', '.join(["'" + i[1] + "'" for i in CodeFeature.count]),
                file=f)
        print('# identifier, lineno, size, 1', file=f)

    def __init__(self, filename):
      try:
        self.features = {}
        self.features['identifier'] = 0
        for i in self.keywords: self.features[i] = 0
        for i in self.count: self.features[i[0]] = 0
        self.size = 0
        with open(filename) as f:
            for count, line in enumerate(f):
                self._parseLine(line)
        self.lineno = count + 1
        log('@feature(%s): %s' % (filename, self.features))

        # features IS RESET AFTER COLLECTION.
        self._toLeastSquaresFeatureVector()
      except Exception:
        traceback.print_exc()

    def _parseLine(self, line):
        self.size += len(line)
        self.features['identifier'] += len(self.ider.findall(line))
        for m in self.kwre.finditer(line):
            self.features[m.group(0)] += 1
        for c in self.count:
            self.features[c[0]] += line.count(c[1])

    def _matchre(self, line, regex):
        for m in regex.finditer(line):
            self.features[entry] += 1

    # Refer to: numpy.linalg.lstsq
    def _toLeastSquaresFeatureVector(self):
        assert type(self.features) is dict, \
                '_toLeastSquaresFeatureVector is invoked more than once'
        features = self.features
        keywords = [features[i] for i in self.keywords]
        count = [features[i[0]] for i in self.count]
        self.features = keywords + count + \
                [features['identifier'], self.lineno, self.size, 1]


# Measure job size according to task arguments
# Sub-classes should reset self._compute for onerous size computation.
# hint returns True if model is updated.
class JobSize:
    def get(self, opts, cdb, action=None):
        if action is None:
            return None
        return self._compute(opts, cdb, action)

    def hint(self, size, opts, cdb, action=None):
        if action is not None:
            return self._hint(size, opts, cdb, action)
        return False

    def _hint(self, size, opts, cdb, action): return False

    def getModel(self): return None
    def getSummary(self): return None

class LinesOfCodeAsJobSize(JobSize):
    def _compute(self, opts, cdb, action):
        with open(cdb.file) as f:
            for count, _ in enumerate(f):
                pass
        return count + 1

class FeatureEstimatedJobSize(JobSize):
    def __init__(self):
        self.summaries = {}
        self.hints = {}
        self.model = {}

    def getModel(self): return self.model
    def getSummary(self): return self.summaries

    def _getFeature(self, cdb):
        if cdb.file in self.summaries:
            return self.summaries[cdb.file]

        feature = CodeFeature(cdb.file)
        self.summaries[cdb.file] = feature
        return feature

    def _compute(self, opts, cdb, action):
        log('Computing job size for: ' + cdb.file)
        feature = self._getFeature(cdb)

        entry = hash(action)
        if entry not in self.model:
            log('@jobsize(%s) - model N/A: %d' % (cdb.file, feature.lineno))
            return feature.lineno

        ret = 0.0
        for x, m in zip(feature.features, self.model[entry]):
            ret += x * m
        log('@jobsize(%s) - from model: %.3lf' % (cdb.file, ret))
        return ret

    def _hint(self, size, opts, cdb, action):
        # Build feature for current cdb if not computed before.
        self._getFeature(cdb)

        # Add hint.
        entry = hash(action)
        log('@hint[%x](%s): %.3lf' % (entry, cdb.file, size))
        self.hints.setdefault(entry, {})[cdb.file] = size
        if len(self.hints[entry]) % Default.RecomputeModelAfterHints != 0:
            return False

        # Compute a model with numpy.linalg.lstsq
        hints = [self.hints[entry][i] for i in self.hints[entry]]
        log('hints: ' + str(hints))
        summaries = [self.summaries[i].features for i in self.hints[entry]]
        log('summaries: ' + str(summaries))
        try:
            farray = np.vstack(summaries)
            model = np.linalg.lstsq(farray, hints, rcond=None)[0]
            self.model[entry] = model
        except BaseException as e:
            traceback.print_exc()
            warn(str(e))
            warn('When hinting action [%s] (%x) for file %s: %.3lf' \
                    % (action.summarize(), entry, cdb.file, size))
            warn('hints: ' + str(hints))
            warn('summaries: ' + str(summaries))
            return False
        log('@model[%x]: %s' % (entry, str(model)))
        return True


class WorklistItem:
    def __init__(self, func, *args):
        self.func = func
        self.args = args

    def run(self):
        self.func(*self.args)
        return True

    def getArgs(self): return self.args

class WorklistStop:
    def run(self): return False


# Wrapping a worklist item or stop, determining their order according to the
# sorting strategy.
# Override itemlt to override the sorting strategy.
# DO NOT override __lt__ as it determines the order of stop and items.
#
# Worklist order:
# - STOP is always the largest element
# - if size is not determined, order by id: FIFO
# - sized order is determined by sub-classes comparison
class WorklistOrder:
    def __init__(self, item): self.item = item
    def getArgs(self): return self.item.args
    def run(self): return self.item.run()

    def isStop(self): return type(self.item) is WorklistStop
    def hasSize(self): return hasattr(self, 'size')

    def __lt__(self, other):
        # STOPs are always the largest.
        if self.isStop(): return False
        if other.isStop(): return True
        # if unsized, order by ID.
        if not self.hasSize() or not other.hasSize():
            return self.id < other.id
        # if both are sized, order by size.
        return self.itemlt(other)

# Longest job first order:
# - CDB tasks to front: the least
# - Decending order of size: the larger the less
class LongestJobFirstWorklistOrder(WorklistOrder):
    def itemlt(self, other):
        if self.size is None: return True
        if other.size is None: return False
        return self.size > other.size

# Shortest job first order:
# - CDB tasks to back: the largest
# - Decending order of size: the less the less
class ShortestJobFirstWorklistOrder(WorklistOrder):
    def itemlt(self, other):
        if self.size is None: return False
        if other.size is None: return True
        return self.size < other.size


# Add interfaces of SortedWorklist to Queue.
class NormalQueue(Queue):
    def sort(self): pass
    def hint(self, item, duration): pass
    def getSortDurations(self): return []
    def getModel(self): return None
    def getSize(self, item): return 0

class SortedWorklist(PriorityQueue):
    jobsize = None
    order = None

    def getSortDurations(self): return self.durations
    def getModel(self): return self.jobsize.getModel()

    def getSize(self, item): return self.jobsize.get(*item.getArgs())

    def _init(self, _):
        super()._init(_)
        self.id = 0
        self.sorted = False
        self.durations = []

    def _put(self, item):
        item = self.order(item)
        if item.isStop():
            # STOP is always the largest item, append directly will not break
            # the heap constraints.
            self.queue.append(item)
            return

        # It is safe to directly use self.id, as lock is locked.
        self.id += 1
        item.id = self.id

        ## Do not compute job size if there is idle workers.
        #if self._qsize() > 2: # Locked, self.qsize will lead to dead lock.
        #    item.size = self.getSize(item)
        item.size = self.getSize(item)

        # Put item into heap.
        try:
            super()._put(item)
        except Exception as e:
            traceback.print_exc()

    def sort(self):
        # Do not sort if there is too little items.
        # Force sorting for the first time when upgrading loc to size.
        qsize = self.qsize()
        log('qsize = ' + str(qsize))
        if not self.sorted:
            self.sorted = True
            log('Force first sorting.')
        elif qsize <= 5:
            log('Abort sorting.')
            return
        else:
            log('Sorting worklist.')
        begin = time.time()
        with self.mutex:
            for item in self.queue:
                if not item.isStop():
                    item.size = self.jobsize.get(*item.getArgs())
            heapq.heapify(self.queue)
            self.not_empty.notify()
        end = time.time()
        self.durations.append((begin, end))

    def hint(self, item, duration):
        if item.isStop(): return False
        return self.jobsize.hint(duration, *item.getArgs())

class WorklistManager:
    def __init__(self, worklist, output):
        self.output = output
        self.worklist = worklist
        self.stop = mp.Manager().Value(bool, False)
        self.hints = mp.Manager().Queue()
        self.hintlist = mp.Manager().list()
        self.sorter = mp.Process(target=self._sort)
        self.sorter.daemon = True
        self.sorter.start()
        log('Sorter process %d starts.' % self.sorter.pid)

    def hint(self, item, duration):
        duration *= 1000
        self.hints.put((item, duration))
        self.hintlist.append((item, duration))

    def join(self):
        self.stop.set(True)
        self.sorter.join()
        log('Sorter process %d joins.' % self.sorter.pid)

    def dump(self):
        if not self.output: return
        with open(os.path.join(self.output, 'sorter.log'), 'w') as f:
            for i in self.worklist.getSortDurations():
                f.write('%lf %lf\n' % (i[0], i[1]))
        model = self.worklist.getModel()
        if model:
            with open(os.path.join(self.output, 'model.log'), 'w') as f:
                CodeFeature.dumpFeatures(f)
                f.write(str(model))
        with open(os.path.join(self.output, 'predictions.log'), 'w') as f:
            f.write('<file> <online> <final> <execution>\n')
            for item, duration in list(self.hintlist):
                opts, cdb, action = \
                        (lambda o, c, a=None: (o, c, a))(*item.getArgs())
                size = 0.0
                if hasattr(item, 'size') and type(item.size) is not int:
                    size = item.size
                if not action: continue
                f.write('%s %lf %lf %lf\n' % (
                    cdb.file, size, self.worklist.getSize(item), duration))

    def _sort(self):
        while not self.stop.get():
            try:
                if not self.worklist.hint(*self.hints.get_nowait()):
                    continue
            except QueueEmptyException:
                continue
            self.worklist.sort()


# NOTE: THINK AGAIN BEFORE MODIFYING THE IMPLEMENTATION OF STOPPING.
class TaskPool:
    def __init__(self, opts):
        assert opts.jobs > 0, 'Invalid pool size.'
        logdirformat = '-'.join([
            'logs', opts.scheduler, opts.filesize, '%y%m%d%H%M%S'])
        stamp = time.strftime(logdirformat, time.localtime())
        self.output = os.path.join(opts.output, stamp)
        mkdir(self.output)
        self.procs = []
        self.tasks = mp.Manager().SelectedWorkList()
        self.taskManager = WorklistManager(self.tasks, self.output)
        for i in range(opts.jobs):
            proc = mp.Process(target=self._run_task)
            proc.daemon = True
            proc.start()
            log('Task process %d starts.' % proc.pid)
            self.procs.append(proc)

    def addTask(self, *args):
        self.tasks.put(WorklistItem(*args))

    def join(self):
        for i in self.procs:
            self.tasks.put(WorklistStop())
        for i in self.procs:
            i.join()
            log('Task process %d joins.' % i.pid)
        self.taskManager.join()

    def _run_task(self):
        durations = [(0.0, time.time())]
        while True:
            job = self.tasks.get()
            begin = time.time()
            if not job.run():
                break
            end = time.time()
            durations.append((begin, end))
            self.taskManager.hint(job, end - begin)
        durations.append((time.time(), 0.0))
        if self.output:
            name = 'taskprocess-%d.log' % os.getpid()
            with open(os.path.join(self.output, name), 'w') as f:
                for i in durations:
                    f.write('%lf %lf\n' % (i[0], i[1]))


def GetIndex(container, index, root='<root>'):
    if index not in container:
        raise SyntaxError('Index "%s" not found in %s' % (index, root))
    return container[index]


def GetIndexOrNone(container, index):
    return container[index] if index in container else None


class CompilerActionControl:
    def __init__(self, title, args, extname=None, outopt=None):
        self.title = title
        self.args = args
        if extname:
            self.hasOutput = True
            self.extname = extname
            self.outopt = outopt if outopt is not None else '-o'
            assert isinstance(self.extname, str) or \
                    isinstance(self.extname, list), \
                    'Index "extname" can only be string or list'
        else:
            self.hasOutput = False

    def summarize(self):
        ret = 'compiler: ' + str(self.args)
        if self.hasOutput:
            ret += ', ' + str(self.outopt)
        return ret

    def __hash__(self):
        return hash(self.summarize())

    def CreateFromPluginAction(action):
        title = GetIndex(action, 'title', 'action')
        args = GetIndex(action, 'args', 'action')
        extname = GetIndexOrNone(action, 'extname')
        outopt = GetIndexOrNone(action, 'outopt')
        return CompilerActionControl(title, args, extname, outopt)

    def getOutputExtensionName(self, language):
        if not self.hasOutput:
            return None
        if isinstance(self.extname, str):
            return self.extname
        if language == 'c':
            return self.extname[0]
        if language == 'c++':
            return self.extname[1]
        assert False, 'UNREACHABLE: cannot determine extname.'

    def getOutputName(self, outdir, ccdb):
        assert os.path.isabs(ccdb.file), "'file' in cdb unit is not abspath"
        return outdir + ccdb.file + self.getOutputExtensionName(ccdb.language)


class ClangToolActionControl:
    def __init__(self, title, tool, args, extname=None, stdout=None,
            stderr=None):
        self.title = title
        self.tool = tool
        self.args = args
        self.extname = extname
        self.stdout = stdout
        self.stderr = stderr
        assert not (self.stdout and self.stderr), \
                'Cannot accept both stdout and stderr as output.'
        if self.extname:
            assert self.stdout or self.stderr, \
                    'Capture output from either stdout or stderr'

    def summarize(self):
        return 'tooling: ' + self.tool + ', ' + str(self.args)

    def __hash__(self):
        return hash(self.summarize())

    def CreateFromPluginAction(action):
        title = GetIndex(action, 'title', 'action')
        tool = GetIndex(action, 'tool', 'action')
        args = GetIndex(action, 'args', 'action')
        extname = GetIndexOrNone(action, 'extname')
        stdout, stderr = None, None
        if extname:
            stream = GetIndex(action, 'stream', 'action')
            if stream == 'stdout':
                stdout = proc.PIPE
            if stream == 'stderr':
                stderr = proc.PIPE
            if not stdout and not stderr:
                raise SyntaxError('Invalid value for index "stream" in action')
        return ClangToolActionControl(
                title, tool, args, extname, stdout, stderr)

    def getOutputName(self, outdir, ccdb):
        assert os.path.isabs(ccdb.file), "'file' in cdb unit is not abspath"
        return outdir + ccdb.file + self.extname


def ParsePlugins(plugins):
    ret = []
    for p in set(plugins):
        p = os.path.abspath(p)
        try:
            plugobj = json.load(open(p))
            actionTy = GetIndex(plugobj, 'type')
            action = GetIndex(plugobj, 'action')
            if actionTy == 'CompilerAction':
                ret.append((CompilerAction,
                    CompilerActionControl.CreateFromPluginAction(action)))
                continue
            if actionTy == 'ClangToolAction':
                ret.append((ClangToolAction,
                    ClangToolActionControl.CreateFromPluginAction(action)))
                continue
            raise SyntaxError('Invalid value for index "type"')
        except OSError as eos:
            fatal('Cannot read plugin file: %s' % eos)
        except json.decoder.JSONDecodeError as ejson:
            fatal('Syntax error in plugin file %s: %s' % (p, ejson))
        except SyntaxError as se:
            fatal('Invalid plugin file %s: %s' % (p, se))
        except AssertionError as ae:
            fatal('Invalid plugin file %s: %s' % (p, ae))
    return ret


class Default:
    OutputPath = './panda-output'
    CCompiler = 'clang'
    CXXCompiler = 'clang++'
    ExtDefMapper = 'clang-extdef-mapping'
    CompilationDatabase = os.path.abspath('./compile_commands.json')
    ExternalFunctionMap = 'externalDefMap.txt'
    InvocationList = 'invocations.yaml'
    InputFileList = 'inputs.ifl'
    SourceFileList = 'source-files.txt'

    SelfPath = os.path.realpath(__file__)

    ProgramDescriptionMsg = 'A simple driver for pipelining tools based on ' \
                            'compilation database.'

    RecomputeModelAfterHints = 20
# }}}


def ParseArguments(argv): # {{{
    Panda = argv[0]
    Parser = argparse.ArgumentParser(
            prog='panda', formatter_class=argparse.RawTextHelpFormatter,
            description=Default.ProgramDescriptionMsg)
    Parser.add_argument('--verbose', action='store_true', dest='verbose',
                        help='Verbose output for debug.')
    Parser.add_argument('-f', '--compilation-database', type=str, dest='cdb',
                        help='Customize the input compilation database',
                        default=Default.CompilationDatabase)
    Parser.add_argument('-j', '--jobs', type=int, dest='jobs', default=1,
                        help='Number of jobs can be executed in parallel.')
    Parser.add_argument('-o', '--output', type=str, dest='output',
                        default=Default.OutputPath,
                        help='Write output files to directory.')

    Parser.add_argument(
            '-X', '--syntax', action='store_true', dest='syntax',
            help='Test arguments and source code for frontend errors.')
    Parser.add_argument(
            '-C', '--compile', action='store_true', dest='genobj',
            help='Recompile the source file.')
    Parser.add_argument(
            '-E', '--preprocess', action='store_true', dest='genii',
            help='Generate the preprocessed source file dump.')
    Parser.add_argument(
            '-A', '--gen-ast', action='store_true', dest='genast',
            help='Generate the Clang PCH format source file dump.')
    Parser.add_argument(
            '-B', '--gen-bc', action='store_true', dest='genbc',
            help='Generate the target LLVM bitcode.')
    Parser.add_argument(
            '-R', '--gen-ll', action='store_true', dest='genll',
            help='Generate the target LLVM IR text code.')
    Parser.add_argument(
            '-S', '--gen-asm', action='store_true', dest='genasm',
            help='Generate the target assembly code.')
    Parser.add_argument(
            '-D', '--gen-dep', action='store_true', dest='gendep',
            help='Generate dependency description.')
    Parser.add_argument(
            '-M', '--gen-extdef-mapping', action='store_true', dest='genefm',
            help='Generate the external function map.')
    Parser.add_argument(
            '-P', '--gen-extdef-mapping-ast', action='store_true',
            dest='genefmast', help='Generate the external function map for AST files.')
    Parser.add_argument(
            '-Y', '--gen-invocation-list', action='store_true', dest='genivcl',
            help='Generate the invocation list.')
    Parser.add_argument(
            '-L', '--gen-input-file-list', action='store_true', dest='genifl',
            help='Generate input file list.')
    Parser.add_argument(
            '-F', '--gen-source-file-list', action='store_true', dest='gensfl',
            help='Generate source file list.')

    Parser.add_argument(
            '--analyze', action='store_true', dest='analyze',
            help='Execute Clang Static Analyzer.')
    Parser.add_argument(
            '--plugin', type=str, nargs='*', help='External tools to be executed.')

    Parser.add_argument(
            '--cc', type=str, dest='cc', default=Default.CCompiler,
            help='Customize the C compiler.')
    Parser.add_argument(
            '--cxx', type=str, dest='cxx', default=Default.CXXCompiler,
            help='Customize the C++ compiler.')
    Parser.add_argument(
            '--efmer', type=str, dest='efmer', default=Default.ExtDefMapper,
            help='Customize the external function map generator.')

    Parser.add_argument(
            '--efm', type=str, dest='efm', default=Default.ExternalFunctionMap,
            help='Customize the filename of output external function map.')
    Parser.add_argument(
            '--ivcl', type=str, dest='ivcl', default=Default.InvocationList,
            help='Customize the filename of output invocation list.')
    Parser.add_argument(
            '--ifl', type=str, dest='ifl', default=Default.InputFileList,
            help='Customize the filename of output input file list.')
    Parser.add_argument(
            '--sfl', type=str, dest='sfl', default=Default.SourceFileList,
            help='Customize the filename of output source file list.')

    Parser.add_argument(
            '--sfl-prefix', type=str, dest='sflprefix',
            help='Filter source file list with a prefix. Empty accepts all.')


    Parser.add_argument(
            '--ctu-on-demand-parsing', action='store_true', dest='genodp',
            help='Prepare CTU analysis for on-demand-parsing. (alias to -MYL)')
    Parser.add_argument(
            '--ctu-loading-ast-files', action='store_true', dest='genlaf',
            help='Prepare CTU analysis for loading AST files. (alias to -APL)')

    Parser.add_argument(
            'files', type=str, nargs='*',
            help='Execute actions on specific files in compilation database.')
    Parser.add_argument(
            '--file-list', type=str, dest='filelist',
            help='Execute actions for files on the list.')

    Parser.add_argument(
            '--scheduler-strategy', dest='scheduler', default='fifo',
            choices=['fifo', 'ljf', 'sjf'],
            help='Strategy of scheduling jobs.')
    Parser.add_argument(
            '--measure-job-size-with', dest='filesize', default='loc',
            choices=['loc', 'feature'],
            help='Way of computing job size.')

    opts = Parser.parse_args(argv[1:])
    opts.output = os.path.abspath(opts.output)

    if opts.genodp:
        opts.genefm = True
        opts.genivcl = True
        opts.genifl = True
    if opts.genlaf:
        opts.genast = True
        opts.genefmast = True
        opts.genifl = True
    if opts.files:
        opts.files = set([os.path.abspath(os.path.join(os.path.curdir, i))
            for i in opts.files])
    if opts.filelist:
        try:
            files = set([os.path.abspath(os.path.join(os.path.curdir, i))
                for i in open(opts.filelist).read().split('\n')])
            opts.files = opts.files.union(files) if opts.files else files
        except IOError as e:
            fatal(str(e))
    if opts.plugin:
        opts.plugin = ParsePlugins(opts.plugin)

    # Init log.verbose.
    log('N: Running in verbose mode', opts)
    log('Parsed command line options: ' + str(opts))

    if opts.genefm and opts.genefmast:
        fatal('Option -M and -P are conflict.')

    if not (opts.cdb and os.path.exists(opts.cdb)):
        fatal('Compilation database "' + opts.cdb +'" is unavailable.')

    if opts.jobs <= 0:
        fatal('Invalid count of jobs.')

    # If ctu analysis is enabled, but required files are not generated, add
    # them. Note: invocation list is always required no matter odp or laf mode
    # is prepared.
    # NOTE: ctu analysis disabled for the tool demo version.

    if opts.scheduler == 'fifo':
        mp.Manager().register('SelectedWorkList', NormalQueue)
    elif opts.scheduler == 'ljf':
        SortedWorklist.order = LongestJobFirstWorklistOrder
        mp.Manager().register('SelectedWorkList', SortedWorklist)
    elif opts.scheduler == 'sjf':
        SortedWorklist.order = ShortestJobFirstWorklistOrder
        mp.Manager().register('SelectedWorkList', SortedWorklist)

    if opts.filesize == 'loc':
        mp.Manager().register('SelectedJobSize', LinesOfCodeAsJobSize)
    elif opts.filesize == 'feature':
        mp.Manager().register('SelectedJobSize', FeatureEstimatedJobSize)
    SortedWorklist.jobsize = mp.Manager().SelectedJobSize()

    return opts
# }}}


def CompilerAction(opts, ccdb, action):
    assert ccdb.language != 'Unknown', 'unknown language?'
    compiler = {'c': opts.cc, 'c++': opts.cxx}
    arguments = [compiler[ccdb.language]] + ccdb.arguments + action.args

    if action.hasOutput:
        output = action.getOutputName(opts.output, ccdb)
        print('%s: %s' % (action.title, output))
        arguments += [action.outopt, output]

        # Create directory for output file.
        mkdir(os.path.dirname(output))
    else:
        print('%s for %s' % (action.title, ccdb.file))

    # Execute action commands.
    log('!: ' + json.dumps(arguments))
    with proc.Popen(arguments, cwd=ccdb.directory) as p:
        ret = p.wait()
    return ret


SyntaxOnlyAction = CompilerActionControl(
        'Checking syntax errors', ['-fsyntax-only', '-Wall'])
CompilationAction = CompilerActionControl(
        'Generating object file', ['-c', '-w'], '.o')
PreprocessAction = CompilerActionControl(
        'Generating preprocessed source file', ['-E'], ['.i', '.ii'])
GenerateASTAction = CompilerActionControl(
        'Generating AST dump file', ['-emit-ast', '-w'], '.ast')
GenerateBitcodeAction = CompilerActionControl(
        'Generating LLVM bitcode file', ['-c', '-emit-llvm', '-w'], '.bc')
GenerateLLVMIRAction = CompilerActionControl(
        'Generating LLVM IR file', ['-c', '-emit-llvm', '-S', '-w'], '.ll')
GenerateAssemblyAction = CompilerActionControl(
        'Generating assembly dump file', ['-S', '-w'], '.s')
GenerateDependencyAction = CompilerActionControl(
        'Generating dependency file', ['-fsyntax-only', '-w', '-M'], '.d', '-MF')
# For analyzer, reset output and ctu arguments in self.args with opts.output.
# Checkers in package deadcode are disabled by default, as they usually
# generate only useless reports.
ClangStaticAnalyzerAction = CompilerActionControl(
        'Running static analyzer',
        ['--analyze', '-Xanalyzer', '-analyzer-output=html',
            '-Xanalyzer', '-analyzer-disable-checker=deadcode'])


def ClangToolAction(opts, ccdb, action):
    assert ccdb.language != 'Unknown', 'unknown language?'
    print('%s for %s' % (action.title, ccdb.file))
    actionargs = []
    for i in action.args:
        actionargs.append(i.replace('/path/to/output', opts.output))
    arguments = [action.tool, ccdb.file] + actionargs + ['--', '-w'] + \
             ccdb.arguments
    log('!: ' + json.dumps(arguments))
    content = None
    outstream = None
    with proc.Popen(arguments, stdout=action.stdout, stderr=action.stderr,
            cwd=ccdb.directory) as p:
        if action.stdout:
            outstream = 'stdout'
            content = p.stdout.read().decode('utf-8')
        if action.stderr:
            outstream = 'stderr'
            content = p.stderr.read().decode('utf-8')
        ret = p.wait()
    if content is not None:
        output = action.getOutputName(opts.output, ccdb)
        log('!: Write ' + outstream + ' output to file ' + output)
        mkdir(os.path.dirname(output))
        with open(output, 'w') as fout:
            fout.write(content)
    return ret


# Initialize tool names after argument parsing in function 
# PostArgumentParsingInitializations.
ClangExtDefMappingAction = ClangToolActionControl(
        'Generating raw external function map', Default.ExtDefMapper, [],
        '.extdef', proc.PIPE)


def getExtDefMap(efmfile): return open(efmfile).read()
def GenerateFinalExternalFunctionMap(opts, cdb):
    output = os.path.join(opts.output, opts.efm)
    print('Generating global external function map: ' + output)
    efm = {}
    with mp.Pool(opts.jobs) as p:
        for efmcontent in p.map(getExtDefMap,
                [ClangExtDefMappingAction.getOutputName(opts.output, i) \
                        for i in cdb]):
            for efmline in efmcontent.split('\n'):
                try: # The new "<usr-length>:<usr> <path>" format (D102669).
                    lenlen = efmline.find(':')
                    usrlen = int(efmline[:lenlen])
                    usr = efmline[:lenlen + usrlen + 1]
                    path = efmline[lenlen + usrlen + 2:]
                    efm[usr] = path
                except ValueError: # When <usr-length> is not available.
                    efmitem = efmline.split(' ')
                    if len(efmitem) == 2:
                        efm[efmitem[0]] = efmitem[1]
    with open(output, 'w') as fout:
        for usr in efm:
            path = efm[usr]
            if opts.genefmast or opts.genast:
                path = opts.output + path + '.ast'
            fout.write('%s %s\n' % (usr, path))


def GenerateInvocationListAction(opts, cdb):
    output = os.path.join(opts.output, opts.ivcl)
    print('Generating invocation list: ' + output)

    resourceDir = '-resource-dir='
    with proc.Popen(['clang', '-print-resource-dir'], stdout=proc.PIPE) as p:
        resourceDir += p.stdout.read().decode('utf-8').strip()

    mkdir(os.path.dirname(output))
    with open(output, 'w') as fout:
        for ccdb in cdb:
            ivcl = [ccdb.compiler] + ccdb.arguments + \
                    ['-c', '-working-directory=' + ccdb.directory, resourceDir]
            content = json.dumps({ccdb.file : ivcl})
            fout.write(content[1:-1] + '\n')


def GenerateSourceFileListActionCollect(argv):
    (ccdb, depfile) = argv
    ret = set()
    if not os.path.isfile(depfile):
        warn('Rerun with -D to generate dependency file ' + depfile)
        return ret
    for i in open(depfile).read().split():
        if not i or i == '\\' or i[-1] == ':':
            continue
        name = os.path.abspath(os.path.join(ccdb.directory, i))
        if os.path.isfile(name):
            ret.add(name)
    return ret

def GenerateSourceFileListAction(opts, cdb):
    output = os.path.join(opts.output, opts.sfl)
    print('Generating source file list: ' + output)

    files = None
    jobs = [(i, GenerateDependencyAction.getOutputName(opts.output, i)) \
            for i in cdb]
    with mp.Pool(opts.jobs) as pool:
        files = list(set.union(
            *pool.map(GenerateSourceFileListActionCollect, jobs)))
    files.sort()

    mkdir(os.path.dirname(output))
    with open(output, 'w') as fout:
        for i in files:
            if not opts.sflprefix or i.startswith(opts.sflprefix):
                fout.write(i + '\n')


def GenerateInputFileListAction(opts, cdb):
    output = os.path.join(opts.output, opts.ifl)
    print('Generating input file list: ' + output)
    mkdir(os.path.dirname(output))
    with open(output, 'w') as fout:
        for ccdb in cdb:
            fout.write(ccdb.file + '\n')


def PostArgumentParsingInitializations(opts):
    # Set analyzer output path and ctu arguments.
    ClangStaticAnalyzerAction.args += [
            '-o', os.path.join(opts.output, 'csa-reports')
            ]
    if opts.verbose:
        ClangStaticAnalyzerAction.args += [
                '-Xanalyzer', '-analyzer-display-progress'
                ]
    # NOTE: ctu analysis disabled for the tool demo version.
    # Set clang-extdef-mapping tool.
    ClangExtDefMappingAction.tool = opts.efmer

    # Dump summaries of all actions.
    if not opts.verbose:
        return
    log(SyntaxOnlyAction.summarize())
    log(CompilationAction.summarize())
    log(PreprocessAction.summarize())
    log(GenerateASTAction.summarize())
    log(GenerateBitcodeAction.summarize())
    log(GenerateLLVMIRAction.summarize())
    log(GenerateAssemblyAction.summarize())
    log(GenerateDependencyAction.summarize())
    log(ClangStaticAnalyzerAction.summarize())
    log(ClangExtDefMappingAction.summarize())
    if opts.plugin:
        for p in opts.plugin:
            log(p[1].summarize())


def CreateCompilationDatabaseObjectAction(opts, pool):
    def action(ccmd):
        ccdb = CompileCommands(ccmd)
        if opts.files and ccdb.file not in opts.files:
            log('Skip file "%s"' % ccdb.file)
            return ccdb
        if ccdb.language == 'Unknown':
            warn('Skip file "%s" for unsupported language type' % ccdb.file)
            return ccdb

        if opts.syntax:
            pool.addTask(CompilerAction, opts, ccdb, SyntaxOnlyAction)
        if opts.genobj:
            pool.addTask(CompilerAction, opts, ccdb, CompilationAction)
        if opts.genii:
            pool.addTask(CompilerAction, opts, ccdb, PreprocessAction)
        if opts.genast:
            pool.addTask(CompilerAction, opts, ccdb, GenerateASTAction)
        if opts.genbc:
            pool.addTask(CompilerAction, opts, ccdb, GenerateBitcodeAction)
        if opts.genll:
            pool.addTask(CompilerAction, opts, ccdb, GenerateLLVMIRAction)
        if opts.genasm:
            pool.addTask(CompilerAction, opts, ccdb, GenerateAssemblyAction)
        if opts.gendep:
            pool.addTask(CompilerAction, opts, ccdb, GenerateDependencyAction)
        if opts.genefm or opts.genefmast:
            pool.addTask(ClangToolAction, opts, ccdb, ClangExtDefMappingAction)
        # As no-ctu analysis is single file operation, they can be executed
        # together with other compiler and clang tooling actions.
        if opts.analyze:
            pool.addTask(CompilerAction, opts, ccdb, ClangStaticAnalyzerAction)
        # Add plugin actions.
        if opts.plugin:
            for p in opts.plugin:
                pool.addTask(p[0], opts, ccdb, p[1])
        return ccdb
    return action


def AddCompilationDatabaseActions(opts, pool, cdb):
    if opts.genivcl:
        pool.addTask(GenerateInvocationListAction, opts, cdb)
    if opts.genifl:
        pool.addTask(GenerateInputFileListAction, opts, cdb)


def ExecuteFullCompilationDatabaseAction(opts, cdb):
    if opts.genefm or opts.genefmast:
        GenerateFinalExternalFunctionMap(opts, cdb)
    if opts.gensfl:
        GenerateSourceFileListAction(opts, cdb)
    # For ctu analysis, execute analyzer after all required files are
    # generated.
    # NOTE: ctu analysis disabled for the tool demo version.


def main(argv):
    opts = ParseArguments(argv)
    PostArgumentParsingInitializations(opts)
    PrintExcutionInfo.start_time = time.time()
    pool = TaskPool(opts)
    action = CreateCompilationDatabaseObjectAction(opts, pool)
    with open(opts.cdb) as fcdb:
        cdb = json.load(fcdb, object_hook=action)
    AddCompilationDatabaseActions(opts, pool, cdb)
    pool.join()
    ExecuteFullCompilationDatabaseAction(opts, cdb)
    PrintExcutionInfo()
    pool.taskManager.dump()


if __name__ == '__main__':
    main(sys.argv)
